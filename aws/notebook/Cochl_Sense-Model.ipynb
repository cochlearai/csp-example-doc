{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Deploy Cochl.Sense Model Package from AWS Marketplace\n\n[Cochl.Sense](https://cochl.ai) is an AI-powered audio recognition API that analyzes audio and detects various sound events such as music, speech, sirens, alarms, and more.\n\nThis notebook demonstrates how to deploy and use the Cochl.Sense model from AWS Marketplace using Amazon SageMaker.\n\n## Contents\n\n1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n2. [Set up the environment](#2.-Set-up-the-environment)\n3. [Real-time Inference](#3.-Real-time-Inference)\n4. [Asynchronous Inference](#4.-Asynchronous-Inference)\n5. [Batch Transform](#5.-Batch-Transform)\n\n## Usage Instructions\n\nYou can run this notebook one cell at a time by pressing Shift+Enter.\n\n**Note**: Each inference section (Real-time, Async, Batch) is independent and can be run separately. You only need to run sections 1-2 first, then choose whichever inference method you need."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subscribe to the model package\n",
    "\n",
    "To subscribe to the model package:\n",
    "\n",
    "1. Open the model package listing page: **Cochl.Sense**\n",
    "2. On the AWS Marketplace listing, click on the **Continue to Subscribe** button.\n",
    "3. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agree with EULA, pricing, and support terms.\n",
    "4. Once you click on **Continue to configuration** button and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3.\n",
    "\n",
    "Copy the ARN corresponding to your region and specify it in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up the environment\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "This notebook requires Python 3.8+ and the following packages. If you're running this notebook locally (not on SageMaker), you may need to set up a virtual environment and install the required packages.\n",
    "\n",
    "#### Option 1: Using virtual environment (recommended for local development)\n",
    "\n",
    "```bash\n",
    "# Create and activate virtual environment\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n",
    "\n",
    "# Install required packages\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "#### Option 2: Install directly in notebook\n",
    "\n",
    "Run the cell below to install packages directly.\n",
    "\n",
    "#### AWS CLI Configuration (required for local development)\n",
    "\n",
    "If you're running this notebook locally, you need to configure AWS credentials:\n",
    "\n",
    "```bash\n",
    "aws configure\n",
    "```\n",
    "\n",
    "You will be prompted to enter:\n",
    "- AWS Access Key ID\n",
    "- AWS Secret Access Key\n",
    "- Default region name (e.g., `us-east-1`)\n",
    "- Default output format (e.g., `json`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if packages are not installed (skip if running on SageMaker)\n",
    "# !pip install boto3 sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model package ARN from AWS Marketplace\n",
    "model_package_arn = \"<your-model-package-arn>\"  # Replace with your ARN from Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import sagemaker\n",
    "from sagemaker import ModelPackage, get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Default Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Real-time Inference\n\nReal-time inference provides synchronous predictions with low latency. The maximum payload size is **25 MB** with a processing time limit of **60 seconds**.\n\n### Create a real-time endpoint",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create model and deploy a real-time endpoint\nrt_model_name = f\"cochl-sense-rt-model-{int(time.time())}\"\nrt_model = ModelPackage(\n    role=role,\n    model_package_arn=model_package_arn,\n    sagemaker_session=sagemaker_session,\n    name=rt_model_name\n)\n\nrealtime_endpoint_name = f\"cochl-sense-realtime-{int(time.time())}\"\ninstance_type = \"ml.g4dn.xlarge\"  # GPU instance for faster inference\n\nrt_predictor = rt_model.deploy(\n    initial_instance_count=1,\n    instance_type=instance_type,\n    endpoint_name=realtime_endpoint_name\n)\n\nprint(f\"Model created: {rt_model_name}\")\nprint(f\"Endpoint deployed: {realtime_endpoint_name}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for the endpoint to be ready\n",
    "\n",
    "Endpoint deployment typically takes about **7 minutes**. You can check the endpoint status in the [SageMaker Console](https://console.aws.amazon.com/sagemaker/home#/endpoints). Proceed to the next step once the endpoint status is `InService`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input data\n",
    "\n",
    "The input must be raw audio binary data. Supported formats:\n",
    "- `audio/mp3`\n",
    "- `audio/wav`\n",
    "- `audio/ogg`\n",
    "- `application/octet-stream` (auto-detection)\n",
    "- `audio/x-raw; rate={sample_rate}; format={sample_format}; channels={num_channels}` (for raw PCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample audio file\n",
    "rt_audio_file_path = \"data/sample.mp3\"\n",
    "rt_content_type = \"audio/mp3\"\n",
    "\n",
    "with open(rt_audio_file_path, \"rb\") as f:\n",
    "    rt_audio_data = f.read()\n",
    "\n",
    "# Initialize clients\n",
    "rt_runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "rt_sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "print(f\"Loaded audio file: {rt_audio_file_path}\")\n",
    "print(f\"File size: {len(rt_audio_data)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the endpoint\n",
    "rt_response = rt_runtime_client.invoke_endpoint(\n",
    "    EndpointName=realtime_endpoint_name,\n",
    "    ContentType=rt_content_type,\n",
    "    Body=rt_audio_data\n",
    ")\n",
    "\n",
    "rt_result = json.loads(rt_response[\"Body\"].read().decode(\"utf-8\"))\n",
    "print(json.dumps(rt_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke with sensitivity control (optional)\n",
    "\n",
    "You can adjust the detection sensitivity using `CustomAttributes` as a JSON string:\n",
    "\n",
    "- `default_sensitivity`: Default sensitivity for all tags. Range: [-2, 2] (integer). Default: 0\n",
    "- `tags_sensitivity`: Per-tag sensitivity adjustment. Range: [-2, 2] (integer)\n",
    "\n",
    "Sensitivity can be set globally or individually per tag:\n",
    "- Positive values increase tag appearance (more tags will appear), negative values decrease it (fewer tags will appear).\n",
    "- If certain tags are not being detected frequently, try increasing the sensitivity.\n",
    "- If you experience too many false detections, lowering the sensitivity may help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke with custom sensitivity settings\n",
    "rt_custom_attributes = json.dumps({\n",
    "    \"default_sensitivity\": 1,\n",
    "    \"tags_sensitivity\": {\"Drum\": -2, \"Sing\": 2}\n",
    "})\n",
    "\n",
    "rt_response = rt_runtime_client.invoke_endpoint(\n",
    "    EndpointName=realtime_endpoint_name,\n",
    "    ContentType=rt_content_type,\n",
    "    CustomAttributes=rt_custom_attributes,\n",
    "    Body=rt_audio_data\n",
    ")\n",
    "\n",
    "rt_result = json.loads(rt_response[\"Body\"].read().decode(\"utf-8\"))\n",
    "print(json.dumps(rt_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the real-time endpoint\n",
    "\n",
    "Delete the endpoint to avoid incurring charges when not in use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Delete the real-time endpoint and model\nrt_sagemaker_client.delete_endpoint(EndpointName=realtime_endpoint_name)\nrt_sagemaker_client.delete_model(ModelName=rt_model_name)\nprint(f\"Endpoint deleted: {realtime_endpoint_name}\")\nprint(f\"Model deleted: {rt_model_name}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Asynchronous Inference\n",
    "\n",
    "Asynchronous inference is suitable for large files or when you don't need immediate results. The maximum payload size is **1 GB** with a processing time limit of **60 minutes**.\n",
    "\n",
    "### Create an asynchronous inference endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sagemaker.async_inference import AsyncInferenceConfig\n\n# Create model for async inference\nasync_model_name = f\"cochl-sense-async-model-{int(time.time())}\"\nasync_model = ModelPackage(\n    role=role,\n    model_package_arn=model_package_arn,\n    sagemaker_session=sagemaker_session,\n    name=async_model_name\n)\n\nasync_endpoint_name = f\"cochl-sense-async-{int(time.time())}\"\nasync_output_path = f\"s3://{bucket}/cochl-sense/async-output/\"\nasync_failure_path = f\"s3://{bucket}/cochl-sense/async-failure/\"\n\n# Create async inference config\nasync_config = AsyncInferenceConfig(\n    output_path=async_output_path,\n    failure_path=async_failure_path,\n    max_concurrent_invocations_per_instance=4\n)\n\n# Deploy async endpoint\nasync_predictor = async_model.deploy(\n    initial_instance_count=1,\n    instance_type=\"ml.g4dn.xlarge\",\n    endpoint_name=async_endpoint_name,\n    async_inference_config=async_config\n)\n\nprint(f\"Model created: {async_model_name}\")\nprint(f\"Async endpoint deployed: {async_endpoint_name}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for the async endpoint to be ready\n",
    "\n",
    "Endpoint deployment typically takes about **7 minutes**. You can check the endpoint status in the [SageMaker Console](https://console.aws.amazon.com/sagemaker/home#/endpoints). Proceed to the next step once the endpoint status is `InService`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload input file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clients and load audio file\n",
    "async_s3_client = boto3.client(\"s3\")\n",
    "async_runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "async_sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "async_audio_file_path = \"data/sample.mp3\"\n",
    "\n",
    "# Upload audio file to S3\n",
    "async_s3_input_key = \"cochl-sense/async-input/sample.mp3\"\n",
    "async_s3_input_location = f\"s3://{bucket}/{async_s3_input_key}\"\n",
    "\n",
    "async_s3_client.upload_file(async_audio_file_path, bucket, async_s3_input_key)\n",
    "print(f\"Uploaded to: {async_s3_input_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the async endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke async endpoint\n",
    "async_response = async_runtime_client.invoke_endpoint_async(\n",
    "    EndpointName=async_endpoint_name,\n",
    "    InputLocation=async_s3_input_location,\n",
    "    ContentType=\"audio/mp3\",\n",
    "    Accept=\"application/json\"\n",
    ")\n",
    "\n",
    "async_output_location = async_response[\"OutputLocation\"]\n",
    "print(f\"Output will be stored at: {async_output_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for and retrieve the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll for the result\n",
    "import urllib.parse\n",
    "\n",
    "async_parsed_url = urllib.parse.urlparse(async_output_location)\n",
    "async_output_bucket = async_parsed_url.netloc\n",
    "async_output_key = async_parsed_url.path.lstrip(\"/\")\n",
    "\n",
    "async_max_retries = 60\n",
    "async_retry_interval = 5\n",
    "\n",
    "for i in range(async_max_retries):\n",
    "    try:\n",
    "        async_obj = async_s3_client.get_object(Bucket=async_output_bucket, Key=async_output_key)\n",
    "        async_result = json.loads(async_obj[\"Body\"].read().decode(\"utf-8\"))\n",
    "        print(\"Inference completed!\")\n",
    "        print(json.dumps(async_result, indent=2))\n",
    "        break\n",
    "    except async_s3_client.exceptions.NoSuchKey:\n",
    "        print(f\"Waiting for result... ({i+1}/{async_max_retries})\")\n",
    "        time.sleep(async_retry_interval)\n",
    "else:\n",
    "    print(\"Timeout waiting for async inference result.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the async endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Delete the async endpoint and model\nasync_sagemaker_client.delete_endpoint(EndpointName=async_endpoint_name)\nasync_sagemaker_client.delete_model(ModelName=async_model_name)\nprint(f\"Endpoint deleted: {async_endpoint_name}\")\nprint(f\"Model deleted: {async_model_name}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Transform\n",
    "\n",
    "Batch Transform is suitable for running inference on large datasets stored in S3.\n",
    "\n",
    "For datasets with mixed audio formats (mp3, wav, ogg), use `application/octet-stream` as the ContentType to enable auto-detection.\n",
    "\n",
    "### Upload batch input data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create model for batch transform\nbatch_model_name = f\"cochl-sense-batch-model-{int(time.time())}\"\nbatch_model = ModelPackage(\n    role=role,\n    model_package_arn=model_package_arn,\n    sagemaker_session=sagemaker_session,\n    name=batch_model_name\n)\n\n# Initialize clients and set paths\nbatch_s3_client = boto3.client(\"s3\")\nbatch_sagemaker_client = boto3.client(\"sagemaker\")\n\nbatch_audio_file_path = \"data/sample.mp3\"\n\nbatch_input_prefix = \"cochl-sense/batch-input/\"\nbatch_output_prefix = \"cochl-sense/batch-output/\"\n\nbatch_input_path = f\"s3://{bucket}/{batch_input_prefix}\"\nbatch_output_path = f\"s3://{bucket}/{batch_output_prefix}\"\n\n# Upload sample file\nbatch_s3_client.upload_file(batch_audio_file_path, bucket, f\"{batch_input_prefix}sample.mp3\")\nprint(f\"Model created: {batch_model_name}\")\nprint(f\"Batch input path: {batch_input_path}\")\nprint(f\"Batch output path: {batch_output_path}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and run a batch transform job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "batch_transform_job_name = f\"cochl-sense-batch-{int(time.time())}\"\n\n# Create batch transform job\nbatch_transformer = batch_model.transformer(\n    instance_count=1,\n    instance_type=\"ml.g4dn.xlarge\",\n    output_path=batch_output_path,\n    max_payload=100,  # Max payload size in MB\n    max_concurrent_transforms=1,\n)\n\n# Start the transform job\nbatch_transformer.transform(\n    data=batch_input_path,\n    data_type=\"S3Prefix\",\n    content_type=\"application/octet-stream\",  # Auto-detection for mixed formats\n    split_type=\"None\",\n    job_name=batch_transform_job_name,\n    wait=False\n)\n\nprint(f\"Batch transform job started: {batch_transform_job_name}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the batch transform job\n",
    "\n",
    "The batch transform job typically takes about **7 minutes** to provision and start processing. You can check the job status in the [SageMaker Console](https://console.aws.amazon.com/sagemaker/home#/transform-jobs). Proceed to the next step once the job status is `Completed`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve batch transform results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and display batch transform output files\n",
    "batch_response = batch_s3_client.list_objects_v2(Bucket=bucket, Prefix=batch_output_prefix)\n",
    "\n",
    "if \"Contents\" in batch_response:\n",
    "    for obj in batch_response[\"Contents\"]:\n",
    "        batch_key = obj[\"Key\"]\n",
    "        print(f\"\\n=== {batch_key} ===\")\n",
    "        batch_output_obj = batch_s3_client.get_object(Bucket=bucket, Key=batch_key)\n",
    "        batch_result = json.loads(batch_output_obj[\"Body\"].read().decode(\"utf-8\"))\n",
    "        print(json.dumps(batch_result, indent=2))\n",
    "else:\n",
    "    print(\"No output files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Delete the batch model\n\nDelete the model to avoid incurring charges when not in use.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Delete the batch model\nbatch_sagemaker_client.delete_model(ModelName=batch_model_name)\nprint(f\"Model deleted: {batch_model_name}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Format Reference\n",
    "\n",
    "The inference result is returned in JSON format:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"metadata\": {\n",
    "    \"content_type\": \"audio/mp3\",\n",
    "    \"length_sec\": 3.012,\n",
    "    \"size_byte\": 12345,\n",
    "    \"name\": \"sagemaker_input\"\n",
    "  },\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"tags\": [\n",
    "        {\n",
    "          \"name\": \"Drum\",\n",
    "          \"probability\": 0.51982635\n",
    "        }\n",
    "      ],\n",
    "      \"start_time\": 0,\n",
    "      \"end_time\": 2\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "For available tags, see: https://docs.cochl.ai/sense/home/soundtags/"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Appendix: Unsubscribe from the model package\n\nIf you no longer need the model, you can unsubscribe from the AWS Marketplace:\n\n1. Navigate to **Machine Learning** tab in [Your Software subscriptions page](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_ind498)\n2. Locate the listing that you want to cancel the subscription for, and then click **Cancel Subscription**",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}